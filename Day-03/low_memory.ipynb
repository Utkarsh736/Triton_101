{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8m7_Ap0mV35J"
      },
      "outputs": [],
      "source": [
        "import tabulate\n",
        "import torch\n",
        "\n",
        "import triton\n",
        "import triton.language as tl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "_D4TV-slV9Gy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "FeVn26HTV_pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _dropout(\n",
        "    x_ptr,  # pointer to the input\n",
        "    x_keep_ptr,  # pointer to a mask of 0s and 1s\n",
        "    output_ptr,  # pointer to the output\n",
        "    n_elements,  # number of elements in the `x` tensor\n",
        "    p,  # probability that an element of `x` is changed to zero\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    block_start = pid * BLOCK_SIZE\n",
        "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offsets < n_elements\n",
        "    # Load data\n",
        "    x = tl.load(x_ptr + offsets, mask=mask)\n",
        "    x_keep = tl.load(x_keep_ptr + offsets, mask=mask)\n",
        "    # The line below is the crucial part, described in the paragraph above!\n",
        "    output = tl.where(x_keep, x / (1 - p), 0.0)\n",
        "    # Write-back output\n",
        "    tl.store(output_ptr + offsets, output, mask=mask)"
      ],
      "metadata": {
        "id": "FhUmRQBrV_Xg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout(x, x_keep, p):\n",
        "    output = torch.empty_like(x)\n",
        "    assert x.is_contiguous()\n",
        "    n_elements = x.numel()\n",
        "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
        "    _dropout[grid](x, x_keep, output, n_elements, p, BLOCK_SIZE=1024)\n",
        "    return output"
      ],
      "metadata": {
        "id": "-zWxUUN4WEPN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input tensor\n",
        "x = torch.randn(size=(10, ), device=DEVICE)\n",
        "# Dropout mask\n",
        "p = 0.5\n",
        "x_keep = (torch.rand(size=(10, ), device=DEVICE) > p).to(torch.int32)\n",
        "#\n",
        "output = dropout(x, x_keep=x_keep, p=p)\n",
        "print(tabulate.tabulate([\n",
        "    [\"input\"] + x.tolist(),\n",
        "    [\"keep mask\"] + x_keep.tolist(),\n",
        "    [\"output\"] + output.tolist(),\n",
        "]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8j8M5OkWIyt",
        "outputId": "bc9c26da-357f-48ab-da2b-87d0ee5bc30e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------  ---------  --------  -------  --------  -------  ---------  -------  ---------  --------  ---------\n",
            "input      -0.333515  0.634982  1.42745  0.128211  2.02866  -0.789181  1.89824  -0.529615  0.354243  -0.917423\n",
            "keep mask   1         0         1        0         0         0         0         0         0          1\n",
            "output     -0.66703   0         2.8549   0         0         0         0         0         0         -1.83485\n",
            "---------  ---------  --------  -------  --------  -------  ---------  -------  ---------  --------  ---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seeded Dropout"
      ],
      "metadata": {
        "id": "Wop8KAd_WaB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _seeded_dropout(\n",
        "    x_ptr,\n",
        "    output_ptr,\n",
        "    n_elements,\n",
        "    p,\n",
        "    seed,\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "    # compute memory offsets of elements handled by this instance\n",
        "    pid = tl.program_id(axis=0)\n",
        "    block_start = pid * BLOCK_SIZE\n",
        "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    # load data from x\n",
        "    mask = offsets < n_elements\n",
        "    x = tl.load(x_ptr + offsets, mask=mask)\n",
        "    # randomly prune it\n",
        "    random = tl.rand(seed, offsets)\n",
        "    x_keep = random > p\n",
        "    # write-back\n",
        "    output = tl.where(x_keep, x / (1 - p), 0.0)\n",
        "    tl.store(output_ptr + offsets, output, mask=mask)"
      ],
      "metadata": {
        "id": "Fsz82AByWfaP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seeded_dropout(x, p, seed):\n",
        "    output = torch.empty_like(x)\n",
        "    assert x.is_contiguous()\n",
        "    n_elements = x.numel()\n",
        "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )\n",
        "    _seeded_dropout[grid](x, output, n_elements, p, seed, BLOCK_SIZE=1024)\n",
        "    return output"
      ],
      "metadata": {
        "id": "L_jnFoP8Wf8t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(size=(10, ), device=DEVICE)\n",
        "# Compare this to the baseline - dropout mask is never instantiated!\n",
        "output = seeded_dropout(x, p=0.5, seed=123)\n",
        "output2 = seeded_dropout(x, p=0.5, seed=123)\n",
        "output3 = seeded_dropout(x, p=0.5, seed=512)\n",
        "\n",
        "print(\n",
        "    tabulate.tabulate([\n",
        "        [\"input\"] + x.tolist(),\n",
        "        [\"output (seed = 123)\"] + output.tolist(),\n",
        "        [\"output (seed = 123)\"] + output2.tolist(),\n",
        "        [\"output (seed = 512)\"] + output3.tolist(),\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBtBUjNmWhwP",
        "outputId": "46b1f2ed-2959-4d69-9ca1-6b7c47443273"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------  -------  --------  -------  --------  ----------  --------  ---------  ---------  ---------  ---------\n",
            "input                1.30049  0.173393  0.29441  0.872236  -0.0101135  0.842527  -0.659758  -0.501133  -0.832253  -0.329256\n",
            "output (seed = 123)  0        0.346787  0        0          0          1.68505    0          0         -1.66451   -0.658512\n",
            "output (seed = 123)  0        0.346787  0        0          0          1.68505    0          0         -1.66451   -0.658512\n",
            "output (seed = 512)  0        0         0.58882  1.74447    0          1.68505   -1.31952    0          0          0\n",
            "-------------------  -------  --------  -------  --------  ----------  --------  ---------  ---------  ---------  ---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytkTiR0eWzmo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}